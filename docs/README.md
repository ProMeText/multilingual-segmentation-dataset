# ğŸ“š Documentation â€“ Multilingual Segmentation Dataset

This `docs/` folder contains the full documentation for the **Multilingual Segmentation Dataset**,  
designed to support clarity, reproducibility, and transparency in its construction and usage.

The dataset includes a curated, linguistically informed collection of **raw and segmented excerpts** drawn from historical literary works in multiple medieval languages, primarily Romance.

It supports tasks such as:

- âœ‚ï¸ Sentence segmentation  
- ğŸ“œ Historical linguistic analysis  
- ğŸŒ Cross-linguistic and diachronic comparison of medieval texts  

The documentation outlines segmentation principles, data structures, heuristics, and metadata sources used to compile the corpus.

---

## ğŸ“ `data/` Folder Structure

Each subcorpus (e.g. `lancelot/`, `Multilingual_Aegidius/`) includes its own `raw/` and `segmented/` directories.

### `raw/`  
ğŸ“„ **Cleaned, unsegmented texts**  
- UTF-8 encoded, markup removed  
- Original orthography, punctuation, and spacing preserved  
- No segmentation applied

### `pre_split/`  
ğŸ§¾ **Manually or heuristically segmented excerpts**  
- Extracted from `raw/`  
- Marked with `Â£` for sentence/segment boundaries  
- Available in `.txt` format

### `split/`  
ğŸ”€ **Machine learning partitions**  
- Train/dev/test sets  
- In both `.txt` and `.json`  
- Organized by language (`ca/`, `fr/`, etc.) or multilingual folders

---

## ğŸ› ï¸ Data Preparation

â¡ï¸ See [`segmentation_processing_pipeline.md`](segmentation_processing_pipeline.md) for the full preprocessing workflow.

---

## ğŸ§­ How to Use This Documentation

- **Researchers**: reproduce or extend the dataset using segmentation guidelines  
- **Annotators**: follow language-specific segmentation criteria  
- **Developers**: integrate the dataset into NLP pipelines with the documented structure

---

## ğŸ“« How to Contribute

To contribute new corpora or enrich existing ones, please open an issue in the  
[mulada repository](https://github.com/carolisteia/mulada), which registers new datasets and metadata.

---

## ğŸ“ Complete Documentation Index

### ğŸ“ Annotation Guidelines
- [`annotation_guidelines/segmentation_criteria_en.md`](annotation_guidelines/segmentation_criteria_en.md) â€“ Main principles and heuristics  
- [`annotation_guidelines/main-word-delimiters.json`](annotation_guidelines/main-word-delimiters.json) â€“ Regex-based clause delimiters by language

### âš™ï¸ Processing & Examples
- [`segmentation_processing_pipeline.md`](segmentation_processing_pipeline.md) â€“ Step-by-step preprocessing workflow  
- [`segmentation_exemples.md`](segmentation_exemples.md) â€“ Annotated segmentation examples across languages

### ğŸ¤– Segmentation Model
- [`segmentation_model.md`](segmentation_model.md) â€“ Description of the pretrained multilingual BERT model and training instructions for historical sentence segmentation

### ğŸ“Š Metadata
- [`data.csv`](https://github.com/carolisteia/mulada/blob/main/data.csv) â€“ Metadata for all source texts (languages, genres, editions, etc.)  
> ğŸ“ Maintained at the root of the `mulada` repository.

### ğŸ·ï¸ Repository Structure
- [`README.md`](README.md) â€“ ğŸ“Œ This file
